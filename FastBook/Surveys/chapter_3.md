1. Does ethics provide a list of "right answers"?

	No. Ethics is complicated and context-dependent.

1. How can working with people of different backgrounds help when considering ethical questions?

	People of differing backgrounds will allow them to see things which may not be obvious to you.

1. What was the role of IBM in Nazi Germany? Why did the company participate as it did? Why did the workers participate?

	IBM supplied the Nazis with data tabulation products necessary to track the extermination of Jews and other groups. This was driven from the top, with marketing to Hitler and his leadership. The company president personally approved the 1939 release of their alphabetizing machines to organize deportation.

	IBM also provided regular training and maintenance onsite at the concentration camps.

1. What was the role of the first person jailed in the Volkswagen diesel scandal?

	James Liang, one of the engineers. He was just doing as he was told.

1. What was the problem with a database of suspected gang members maintained by California law enforcement officials?

	It was full of errors. It even included 42 babies added to the database at one year old. No process was in place for correcting mistakes or removing people once they'd been added.

1. Why did YouTube's recommendation algorithm recommend videos of partially clothed children to pedophiles, even though no employee at Google had programmed this feature?

	It seemed to get stuck in a feedback loop, and people ended up abusing said feedback loop.

1. What are the problems with the centrality of metrics?

	When an algorithm has a metric to optimize, it'll do everything it can to optimize that number.

1. Why did Meetup.com not include gender in its recommendation system for tech meetups?

	More men expressed interest than women in tech meetups. As such taking gender into account would cause Meetup's algorithm to recommend fewer tech meetups to women. It would have been a self-reinforcing feedback loop.

1. What are the six types of bias in machine learning, according to Suresh and Guttag?

	- Historical bias.
	- Representation bias.
	- Measurement Bias.
	- Evaluation Bias.
	- Aggregation Bias.
	- Deployment Bias.

1. Give two examples of historical race bias in the US.

	- When doctors are shown identical files, they're much less likely to recommend cardiac catheterization to Black patients.
	- When bargaining for a used car, Black people were offered initial prices $700 higher and received smaller concessions.

1. Where are most images in ImageNet from?

	From the United states and other western countries. As a result models trained on imagenet would perform worse on scenes from other countries and cultures.

1. In the paper "Does Machine Learning Automate Moral Hazard and Error" why is sinusitis found to be predictive of a stroke?

	Because people who have sinusitis generally tend to be people who can regularly visit the doctor. As such, they're the people who would normally get recorded in the machine learning model.

1. What is representation bias?

	Where a model doesn't only reflect a real life situation, but actively amplifies it.

1. How are machines and people different, in terms of their use for making decisions?

	- Machines can create feedback loops, and bias can increase exponentially due to these loops.
	- Machines can amplify bias.
	- Algorithms and human decision makers are used differently. They are not directly interchangeable.

1. Is disinformation the same as "fake news"?

	Disinformation can actually contain bits of truth, or half-truths taken out of context.

1. Why is disinformation through auto-generated text a particularly significant issue?

	Ignoring that deep learning is not particularly great at generating correct responses, it can allow one to at scale create massive disinformation campaigns.

1. What are the five ethical lenses described by the Markkula Center?

	- The rights approach
	- The justice approach
	- The utilitarian approach
	- The common good approach
	- The virtue approach

1. Where is policy an appropriate tool for addressing data ethics issues?

	For when you need to address human rights issues primarily. There are times when ethical decisions for individuals or individual market decisions aren't enough, and you actually need coordinated regulatory action.

